{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training of GPT-2-124-million \n",
    "- add the following bells and whistles to the base version\n",
    "    - learning rate warmup\n",
    "    - cosine decay\n",
    "    - gradient clipping\n",
    "- load pre-trained model from pretrain.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys \n",
    "import math\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.6.0\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer\n",
    "import importlib\n",
    "import tiktoken\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of the raw text: <class 'str'>\n",
      "The beginning of raw text: \n",
      " Chapter 1\n",
      "\n",
      "\n",
      "Happy families are all alike; every un\n"
     ]
    }
   ],
   "source": [
    "# read in raw text\n",
    "pdata = f\"{cwd[:-18]}traditional-NLP/data/\"\n",
    "sys.path.append(pdata)\n",
    "with open(f\"{pdata}anna.txt\" , 'r', encoding='utf-8') as f:\n",
    "    text_data = f.read()\n",
    "print(f\"The type of the raw text: {type(text_data)}\")\n",
    "print(f\"The beginning of raw text: \\n {text_data[:50]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num of characters in Anna Karenina: 1985223\n",
      "total num of tokens in Anna Karenina with BPE tokenizer: 508206\n"
     ]
    }
   ],
   "source": [
    "# inspect raw text and tokens\n",
    "total_characters = len(text_data)\n",
    "print(f\"total num of characters in Anna Karenina: {total_characters}\")\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"total num of tokens in Anna Karenina with BPE tokenizer: {total_tokens}\")\n",
    "# total num of characters in Anna Karenina: 1985223\n",
    "# total num of tokens in Anna Karenina with BPE tokenizer: 508206"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f79acf0edf0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_GPT2_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch dataset dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and dataloader\n",
    "\n",
    "class my_text_dataset(Dataset):\n",
    "\n",
    "    # initialize with n varg in\n",
    "    def __init__(self, raw_text:str, tokenizer, max_length:int, stride:int=1):\n",
    "        # create class attributes\n",
    "        self.input_tokens_x = []\n",
    "        self.target_tokens_y = []\n",
    "\n",
    "        # tokenize the enitre text \n",
    "        tokens = tokenizer.encode(raw_text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # set y as stride number of tokens trailing x \n",
    "        for i in range(0, (len(tokens)-max_length), stride):\n",
    "            x_tmp = tokens[i : (i+max_length)]\n",
    "            y_tmp = tokens[(i+1) : (i+max_length+1)]\n",
    "            self.input_tokens_x.append(torch.tensor(x_tmp))\n",
    "            self.target_tokens_y.append(torch.tensor(y_tmp))\n",
    "\n",
    "    # overwrite the __len__() method to return number of rows in the dataset\n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the number of rows / pairs of x-y sequences in the dataset\"\n",
    "        return len(self.input_tokens_x)\n",
    "    \n",
    "    # overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, data and label (X, y).\"\n",
    "        return self.input_tokens_x[idx], self.target_tokens_y[idx]\n",
    "\n",
    "def my_text_dataloader(raw_text:str, batch_size:int=4, max_length:int=256,\n",
    "                       stride:int=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # create dataset\n",
    "    dataset = my_text_dataset(raw_text, tokenizer, max_length, stride)\n",
    "\n",
    "    # create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split into T, V, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num of characters in Anna Karenina: 1985223\n",
      "Split at character index 1588178 between train and valid sets, and at 1786700 betwee valid and hold sets\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "print(f\"total num of characters in Anna Karenina: {total_characters}\")\n",
    "prop_t, prop_v, prop_h = (0.8,0.1,0.1)\n",
    "split_idx_t, split_idx_v = int(prop_t * total_characters), int((prop_t+prop_v) * total_characters)\n",
    "print(f\"Split at character index {split_idx_t} between train and valid sets, and at {split_idx_v} betwee valid and hold sets\")\n",
    "\n",
    "d_train = text_data[:split_idx_t]\n",
    "d_valid = text_data[split_idx_t:split_idx_v]\n",
    "d_hold  = text_data[split_idx_v:]\n",
    "\n",
    "assert (total_tokens * prop_t) > CONFIG_GPT2_124M[\"context_length\"], \"Not enough tokens for loader_t (training dataloader)\"\n",
    "assert (total_tokens * prop_v) > CONFIG_GPT2_124M[\"context_length\"], \"Not enough tokens for loader_v (validation dataloader)\"\n",
    "assert (total_tokens * prop_h) > CONFIG_GPT2_124M[\"context_length\"], \"Not enough tokens for loader_h (testing dataloader)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_t = my_text_dataloader(\n",
    "    raw_text=d_train,\n",
    "    batch_size=2, # this is only for learning purpose; in practice, batch_size >= 1024 is common\n",
    "    max_length=CONFIG_GPT2_124M[\"context_length\"],\n",
    "    stride=CONFIG_GPT2_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "loader_v = my_text_dataloader(\n",
    "    raw_text=d_valid,\n",
    "    batch_size=2,\n",
    "    max_length=CONFIG_GPT2_124M[\"context_length\"],\n",
    "    stride=CONFIG_GPT2_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# loader_h = my_text_dataloader(\n",
    "#     raw_text=d_hold,\n",
    "#     batch_size=2,\n",
    "#     max_length=CONFIG_GPT2_124M[\"context_length\"],\n",
    "#     stride=CONFIG_GPT2_124M[\"context_length\"],\n",
    "#     drop_last=False,\n",
    "#     shuffle=False,\n",
    "#     num_workers=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 406528\n",
      "Validation tokens: 50944\n",
      "All tokens: 457472\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in loader_t:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in loader_v:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modules and model\n",
    "- key components:\n",
    "    - tokenization - done in my_text_dataloader\n",
    "    - input embedding\n",
    "    - positional encoding\n",
    "    - dropout\n",
    "    - tansformer block\n",
    "        - layernorm\n",
    "        - multiheadattention CONFIG_GPT2_124M[\"n_heads\"] by CONFIG_GPT2_124M[\"n_layers\"]\n",
    "        - droppout+shortcut\n",
    "        - layernorm\n",
    "        - feedford\n",
    "        - dropout+shortcut\n",
    "    - layernorm\n",
    "    - output linear layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multihead_Causal_Attention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, n_heads, dropout_rate, qkv_bias=False):\n",
    "        # inherit from the nn.Module parent \n",
    "        super().__init__() \n",
    "\n",
    "        # make sure d_out is divisible by n_heads (modulous ope, remainder==0)\n",
    "        assert (d_out % n_heads == 0), \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.n_heads = n_heads\n",
    "        # floor division\n",
    "        self.d_head = d_out // n_heads\n",
    "        self.w_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        # add the buffer to create mask and send it to device with the model \n",
    "        # but not update it\n",
    "        self.register_buffer(\n",
    "            'mask',\n",
    "            torch.triu(\n",
    "                torch.ones(context_length,context_length),\n",
    "                diagonal=1)\n",
    "        )\n",
    "        # add the dropout - object from nn.Dropout with param dropout_rate\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # add linear layer to combine heads out\n",
    "        self.combine_heads = nn.Linear(d_out, d_out)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # allowing batching: first is the batch dim of tensors\n",
    "        batch, n_tokens, d_in = x.shape\n",
    "\n",
    "        # initialize the w_query, w_key, w_value \n",
    "        # AND matmul with input embeddings x\n",
    "        queries = self.w_query(x)\n",
    "        keys = self.w_key(x)\n",
    "        values = self.w_value(x)\n",
    "\n",
    "        # ###### split weights for the heads ######\n",
    "        # dims from (batch, n_tokens, d_out) \n",
    "        # to (batch, n_tokens, n_heads, d_head)\n",
    "        queries = queries.view(batch, n_tokens, self.n_heads, self.d_head)\n",
    "        keys = keys.view(batch, n_tokens, self.n_heads, self.d_head)\n",
    "        values = values.view(batch, n_tokens, self.n_heads, self.d_head)\n",
    "        # then to (batch, n_heads, n_tokens, d_head)\n",
    "        queries = queries.transpose(1,2)\n",
    "        keys = keys.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "        # ###### split weights for the heads ######\n",
    "\n",
    "        # attention score query @ key.T \n",
    "        # but remember the dims is (batch, n_tokens, n_heads, d_head) so transpose the last two\n",
    "        # !!! this computes dot product for each head !!!\n",
    "        attention_scores = torch.matmul(queries, keys.transpose(2, 3))\n",
    "\n",
    "        # add causal attention masks \n",
    "        # computeation with trailing underscore are performed in-place\n",
    "        attention_scores.masked_fill_(\n",
    "            # change the mask to boolean (truncated to num of tokens)\n",
    "            self.mask.bool()[:n_tokens, :n_tokens],\n",
    "            # fill value when 1 in mask\n",
    "            -torch.inf\n",
    "        )\n",
    "\n",
    "        # attention weights = normalized attention scores\n",
    "        # scale the attention scores by the sqrt(embedding dimentsion) first \n",
    "        # to improve the training performance by avoiding small gradients.\n",
    "        attention_weights = torch.softmax(\n",
    "            attention_scores / (keys.shape[-1]**0.5),\n",
    "            dim=-1\n",
    "        )\n",
    "\n",
    "        # apply dropout to attention weights \n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # calculate context vector attention weights @ values\n",
    "        # ###### combine across all heads  ######\n",
    "        # dims (batch, n_heads, n_tokens, d_head) to (batch, n_tokens, n_heads, d_head)\n",
    "        context_vectors = torch.matmul(attention_weights, values).transpose(1, 2)\n",
    "        context_vectors = context_vectors.contiguous().view(\n",
    "            batch, n_tokens, self.d_out\n",
    "        )\n",
    "        # Combines heads, where self.d_out= self.n_heads * self.d_head\n",
    "        context_vectors = self.combine_heads(context_vectors)\n",
    "        # ###### combine across all heads  ######\n",
    "\n",
    "\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.LayerNorm(emb_dim)\n",
    "# if we code it out it does the following\n",
    "# each mini-batch in the scenario is all the input embeddings of one context \n",
    "# mean and var came from calc across columns of the emsbeddings for each token\n",
    "# then scale and shif provides a linear transformation\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        # unlike buffers, Parameters will be updated\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.GELU()\n",
    "# when coding it out, it looks like the following\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed forward netword after multihead attention in each transformer block\n",
    "# why does this particular architecture have a 4 x expansion and shrinkage?\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(config[\"emb_dim\"], 4 * config[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * config[\"emb_dim\"], config[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Follows the architecture of GPT-2-124_million\n",
    "    Decoder only transformer\n",
    "\n",
    "    - tansformer block\n",
    "        - layernorm\n",
    "        - multiheadattention CONFIG_GPT2_124M[\"n_heads\"] by CONFIG_GPT2_124M[\"n_layers\"]\n",
    "        - droppout\n",
    "        - shortcut\n",
    "        - layernorm\n",
    "        - feedford\n",
    "        - dropout\n",
    "        - shortcut\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lnorm1 = LayerNorm(config[\"emb_dim\"])\n",
    "        self.mhca = Multihead_Causal_Attention(d_in=config[\"emb_dim\"], \n",
    "                                               d_out=config[\"emb_dim\"], \n",
    "                                               context_length=config[\"context_length\"], \n",
    "                                               n_heads=config[\"n_heads\"], \n",
    "                                               dropout_rate=config[\"drop_rate\"])\n",
    "        self.drop_out = nn.Dropout(p=config[\"drop_rate\"])\n",
    "        self.lnorm2 = LayerNorm(config[\"emb_dim\"])\n",
    "        self.ff = FeedForward(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define shortcut / residual connection for attenion block\n",
    "        residual_conn = x\n",
    "        # layer norm before attention\n",
    "        x = self.lnorm1(x)\n",
    "        # multihead causal attention\n",
    "        x = self.mhca(x)\n",
    "        # dropout \n",
    "        x = self.drop_out(x)\n",
    "        # shortcut / residual connection\n",
    "        x = x + residual_conn\n",
    "\n",
    "        # define residual for FeedForward block\n",
    "        residual_conn = x\n",
    "        # layer norm\n",
    "        x = self.lnorm2(x)\n",
    "        # feedforward\n",
    "        x = self.ff(x)\n",
    "        # drop_out\n",
    "        x = self.drop_out(x)\n",
    "        # residual connection\n",
    "        x = x + residual_conn\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it all together into a model \n",
    "class GPT2_124_model(nn.Module):\n",
    "    \"\"\"\n",
    "    - input embedding\n",
    "    - positional encoding\n",
    "    - dropout\n",
    "    - tansformer block\n",
    "    - layernorm\n",
    "    - output linear layer\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # input embedding\n",
    "        self.input_emb = nn.Embedding(num_embeddings=config[\"vocab_size\"],\n",
    "                                      embedding_dim=config[\"emb_dim\"])\n",
    "        # absolute positional encoding\n",
    "        self.pos_emb = nn.Embedding(num_embeddings=config[\"context_length\"], \n",
    "                                    embedding_dim=config[\"emb_dim\"])\n",
    "        # TO TRY RoPE\n",
    "        # from torchtune.modules import RotaryPositionalEmbeddings\n",
    "        # rope_dim = config[\"emb_dim\"]/config[\"n_head\"]\n",
    "        # self.pos_emb = RotaryPositionalEmbeddings(dim=rope_dim)\n",
    "\n",
    "        # dropout\n",
    "        self.drop_out = nn.Dropout(p=config[\"drop_rate\"])\n",
    "\n",
    "        # transformer block x n_layers times\n",
    "        self.transformer_block = nn.Sequential(\n",
    "            # unpack list comprehension to repeat transformer-block n_layers times\n",
    "            *[TransformerBlock(config) for _ in range(config[\"n_layers\"])]\n",
    "        )    \n",
    "\n",
    "        # layer norm\n",
    "        self.lnorm = LayerNorm(config['emb_dim'])\n",
    "\n",
    "        # final output layer\n",
    "        # expand tokens into logits in vocab_size dimensions\n",
    "        # do not add extra bias \n",
    "        self.out_layer = nn.Linear(in_features=config[\"emb_dim\"],\n",
    "                                   out_features=config[\"vocab_size\"],\n",
    "                                   bias=False)\n",
    "    \n",
    "    def forward(self, input_tokens):\n",
    "        batch_size, seq_len = input_tokens.shape\n",
    "        input_embeddings = self.input_emb(input_tokens)\n",
    "        posit_embeddings = self.pos_emb(torch.arange(seq_len, device=input_tokens.device))\n",
    "        # add positional encoding into input embedding \n",
    "        x = input_embeddings + posit_embeddings\n",
    "        # dropout\n",
    "        x = self.drop_out(x)\n",
    "        # transformer block\n",
    "        x = self.transformer_block(x)\n",
    "        # layer norm\n",
    "        x = self.lnorm(x)\n",
    "        # final output layer -> logits\n",
    "        logits = self.out_layer(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training loop\n",
    "- A typical training loop\n",
    "- loop through all training epochs\n",
    "    - within each epoch, loop through all batches (n_batches = train_size / batch_size)\n",
    "        - reset (from previous batch iter) the loss gradient to zero \n",
    "        - calculate loss on the current batch\n",
    "        - backpropagate loss gradient \n",
    "        - step to update weight and biases for next loop of training\n",
    "        - claculate training and validation losses\n",
    "        - visualize losses and sample texts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define training eval funcs\n",
    "- loss calculation under the hood:\n",
    "    - get the logits from the transformer output layer\n",
    "    - convert logits to probablities with softmax\n",
    "    - get target probabilities \n",
    "    - take (-1) * log (probabilties) [ log(prob)<0 so maximize to 0 or (-1)* to minimize to 0 ]\n",
    "    - take the cross entropy loss between predicted and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss per batch\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "# function to compute loss per loader of data during training and validation\n",
    "# as sum of loss across all batches in the dataloader / number of batches\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    # get the number of batches to compute the loss\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        # iterate over all batches in the dataloader unless num_batches is otherwise given\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    # compute loss across batches \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            # sum loss from each batch \n",
    "            total_loss += loss.item() \n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "# calculate avg loss across train set and valid set respecitively\n",
    "def evaluate_model(model, data_train, data_valid, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(data_train, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(data_valid, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "# encode example text to token ids\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "# decode example token ids to text \n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (Batch, Token) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest logits value\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        # until reacing max_new_tokens\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pre-trained (incomplete) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2_124_model(\n",
       "  (input_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_out): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_block): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lnorm): LayerNorm()\n",
       "  (out_layer): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load & use checkpoint\n",
    "\n",
    "torch.manual_seed(123)\n",
    "checkpoint = torch.load(\"my_gpt2_mdl_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPT2_124_model(CONFIG_GPT2_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model,\n",
    "                  data_train,\n",
    "                  data_valid,\n",
    "                  optimizer,\n",
    "                  num_epochs,\n",
    "                  device,\n",
    "                  eval_frequency,\n",
    "                  eval_iter,\n",
    "                  start_context,\n",
    "                  warmup_step_prop=0.2, \n",
    "                  initial_lr=3e-05, \n",
    "                  min_lr=1e-6,\n",
    "                  tokenizer=tokenizer):\n",
    "    \"\"\"\n",
    "    - loop through all training epochs\n",
    "    - within each epoch, loop through all batches (n_batches = train_size / batch_size)\n",
    "        - reset (from previous batch iter) the loss gradient to zero \n",
    "        - calculate loss on the current batch\n",
    "        - backpropagate loss gradient \n",
    "        - step to update weight and biases for next loop of training\n",
    "        - claculate training and validation losses\n",
    "        - visualize losses and sample texts \n",
    "    \"\"\"\n",
    "    # declare lists to track losses\n",
    "    train_losses, val_losses, track_tokens_seen, track_lrs = [], [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    # retrieve the initial learning rate from the optimizer as the peak lr\n",
    "    peak_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    # if optimizer.param_groups[0][\"lr\"] > 0.01:\n",
    "    #     peak_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    # else: \n",
    "    #     peak_lr = 0.01\n",
    "    \n",
    "    # cal the total num of steps/iteration across the whole training\n",
    "    total_training_steps = len(data_train) * num_epochs\n",
    "    # calc warm_up steps as a proportion to toal training steps\n",
    "    warmup_steps = int(warmup_step_prop * total_training_steps)\n",
    "    # calc lr warmup increatment \n",
    "    lr_increment = (peak_lr - initial_lr) / warmup_steps\n",
    "\n",
    "    # main training loop\n",
    "    # loop through all training epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # set model to training mode\n",
    "        model.train()\n",
    "        # loop through all batches \n",
    "        for input_batch, target_batch in data_train:\n",
    "            # reset (from previous batch iter) the loss gradient to zero \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            ##### add learning rate warm up ######\n",
    "            # keep a count of global iterations (across batches and epochs) taken\n",
    "            global_step += 1\n",
    "            # update learning rate if still in the warmup phase\n",
    "            if global_step < warmup_steps:\n",
    "                lr = initial_lr + global_step * lr_increment\n",
    "            else:\n",
    "                # withtout cosine decay\n",
    "                # lr = peak_lr\n",
    "                # ##### with cosine decay #####\n",
    "                progress = ((global_step - warmup_steps) /\n",
    "                            (total_training_steps - warmup_steps))\n",
    "                lr = min_lr + (peak_lr - min_lr) * 0.5 * (\n",
    "                                1 + math.cos(math.pi * progress)\n",
    "                                )\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "                track_lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "            # calculate loss on the current batch\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            # backpropagate loss gradient \n",
    "            loss.backward()\n",
    "\n",
    "            # ####### gradient clipping #######\n",
    "            # Apply gradient clipping after the warmup phase to avoid exploding gradients\n",
    "            if global_step > warmup_steps:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "            # step to update weight and biases for next loop of training\n",
    "            optimizer.step()\n",
    "            # keep a count of the tokens seen \n",
    "            tokens_seen += input_batch.numel()\n",
    "            \n",
    "            global_step += 1\n",
    "\n",
    "            # print out eval from train and valid data if global steps is divisible by eval_frequency\n",
    "            if global_step % eval_frequency == 0:\n",
    "                # get loss for eval_iter number of batches\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, data_train, data_valid, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1} (Global Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        \n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gradient clipping, if we want to check a max gradient first\n",
    "def find_highest_gradient(model):\n",
    "    max_grad = None\n",
    "    for param in model.parameters():\n",
    "        if param.grad is not None:\n",
    "            grad_values = param.grad.data.flatten()\n",
    "            max_grad_param = grad_values.max()\n",
    "        if max_grad is None or max_grad_param > max_grad:\n",
    "            max_grad = max_grad_param\n",
    "    return max_grad\n",
    "print(find_highest_gradient(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Global Step 000005): Train loss 4.536, Val loss 4.580\n",
      "Epoch 1 (Global Step 000015): Train loss 4.456, Val loss 4.576\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# set an extremely small epoch size for testing only\u001b[39;00m\n\u001b[1;32m     15\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 16\u001b[0m train_losses, val_losses, tokens_seen \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mdata_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43meval_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_context\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     28\u001b[0m execution_time_minutes \u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "Cell \u001b[0;32mIn[21], line 81\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, data_train, data_valid, optimizer, num_epochs, device, eval_frequency, eval_iter, start_context, warmup_step_prop, initial_lr, min_lr, tokenizer)\u001b[0m\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# step to update weight and biases for next loop of training\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# keep a count of the tokens seen \u001b[39;00m\n\u001b[1;32m     83\u001b[0m tokens_seen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m input_batch\u001b[38;5;241m.\u001b[39mnumel()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310torch/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310torch/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310torch/lib/python3.10/site-packages/torch/optim/adamw.py:187\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    174\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    176\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    177\u001b[0m         group,\n\u001b[1;32m    178\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m         state_steps,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[0;32m--> 187\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310torch/lib/python3.10/site-packages/torch/optim/adamw.py:339\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 339\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310torch/lib/python3.10/site-packages/torch/optim/adamw.py:418\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    415\u001b[0m param\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m weight_decay)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "# since we loaded previously trained (incomplete) model\n",
    "# model = GPT2_124_model(CONFIG_GPT2_124M)\n",
    "# model.to(device)\n",
    "# # lr=0.0004\n",
    "# # since warmup + cosine decay, increase the initial lr a bit lr=0.001\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.1)\n",
    "\n",
    "start_context = \"This is a test of the modified \"\n",
    "\n",
    "# set an extremely small epoch size for testing only\n",
    "num_epochs = 2\n",
    "train_losses, val_losses, tokens_seen = training_loop(model=model, \n",
    "                                                      data_train=loader_t, \n",
    "                                                      data_valid=loader_v, \n",
    "                                                      optimizer=optimizer, \n",
    "                                                      num_epochs=num_epochs,\n",
    "                                                      device=device, \n",
    "                                                      eval_frequency=5, \n",
    "                                                      eval_iter=5,\n",
    "                                                      start_context=start_context\n",
    "                                                      )\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n",
    "\n",
    "# canceled training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alternative to loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at example training Epoch 2 (Global Step 001585): Train loss 4.535, Val loss 4.582)\n",
      "Perplexity based on the latest validation loss is 97.66\n",
      "The effective vocabulary size that the model is uncertain about at this step is 97.66\n"
     ]
    }
   ],
   "source": [
    "# The perplexity is often considered more interpretable \n",
    "# because it can be understood as the effective vocabulary size \n",
    "# that the model is uncertain about at each step \n",
    "# (in the example below, that'd be perplexity number of tokens)\n",
    "perplexity = torch.exp(torch.tensor(val_losses[-1]))\n",
    "print(f\"Loss at example training Epoch 2 (Global Step 001585): Train loss 4.535, Val loss 4.582)\")\n",
    "print(f\"Perplexity based on the latest validation loss is {perplexity:.2f}\")\n",
    "print(f\"The effective vocabulary size that the model is uncertain about at this step is {perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model + optimizer params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model only\n",
    "# torch.save(model.state_dict(), \"my_gpt2_mdl.pth\")\n",
    "# save model + optimizers\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"my_gpt2_mdl_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2_124_model(\n",
       "  (input_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_out): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_block): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (lnorm1): LayerNorm()\n",
       "      (mhca): Multihead_Causal_Attention(\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (combine_heads): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (lnorm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lnorm): LayerNorm()\n",
       "  (out_layer): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load & use checkpoint\n",
    "\n",
    "torch.manual_seed(123)\n",
    "checkpoint = torch.load(\"my_gpt2_mdl_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPT2_124_model(CONFIG_GPT2_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
